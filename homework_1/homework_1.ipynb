{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Homework: Introduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this homework, we'll learn more about search and use Elastic Search for practice.\n",
    "\n",
    "> It's possible that your answers won't match exactly. If it's the case, select the closest one.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q1. Running Elastic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run Elastic Search 8.4.3, and get the cluster information. If you run it on localhost, this is how you do it:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```bash\n",
    "curl localhost:9200\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What's the `version.build_hash` value?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's get the FAQ data. You can run this snippet:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```python\n",
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "```\n",
    "\n",
    "Note that you need to have the `requests` library:\n",
    "\n",
    "```bash\n",
    "pip install requests\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ANS: 42f05b9372a9a4a470db3b52817899b99a76ee73"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q2. Indexing the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Index the data in the same way as was shown in the course videos. Make the `course` field a keyword and the rest should be text.\n",
    "\n",
    "Don't forget to install the ElasticSearch client for Python:\n",
    "\n",
    "```bash\n",
    "pip install elasticsearch\n",
    "```\n",
    "\n",
    "Which function do you use for adding your data to elastic?\n",
    "\n",
    "* `insert`\n",
    "* `index`\n",
    "* `put`\n",
    "* `add`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ANS: index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q3. Searching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's search in our index.\n",
    "\n",
    "We will execute a query \"How do I execute a command in a running docker container?\".\n",
    "\n",
    "Use only `question` and `text` fields and give `question` a boost of 4, and use `\"type\": \"best_fields\"`.\n",
    "\n",
    "What's the score for the top ranking result?\n",
    "\n",
    "* 94.05\n",
    "* 84.05\n",
    "* 74.05\n",
    "* 64.05\n",
    "\n",
    "Look at the `_score` field."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ANS: 84.05"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q4. Filtering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's only limit the questions to `machine-learning-zoomcamp`.\n",
    "\n",
    "Return 3 results. What's the 3rd question returned by the search engine?\n",
    "\n",
    "* How do I debug a docker container?\n",
    "* How do I copy files from a different folder into docker container’s working directory?\n",
    "* How do Lambda container images work?\n",
    "* How can I annotate a graph?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ANS: \"How do I copy files from a different folder into docker container’s working directory?\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q5. Building a prompt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we're ready to build a prompt to send to an LLM.\n",
    "\n",
    "Take the records returned from Elasticsearch in Q4 and use this template to build the context. Separate context entries by two linebreaks (`\\n\\n`)\n",
    "```python\n",
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "```\n",
    "\n",
    "Now use the context you just created along with the \"How do I execute a command in a running docker container?\" question\n",
    "to construct a prompt using the template below:\n",
    "\n",
    "```\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "```\n",
    "\n",
    "What's the length of the resulting prompt? (use the `len` function)\n",
    "\n",
    "* 962\n",
    "* 1462\n",
    "* 1962\n",
    "* 2462"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ANS: 1462"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q6. Tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When we use the OpenAI Platform, we're charged by the number of\n",
    "tokens we send in our prompt and receive in the response.\n",
    "\n",
    "The OpenAI python package uses `tiktoken` for tokenization:\n",
    "\n",
    "```bash\n",
    "pip install tiktoken\n",
    "```\n",
    "\n",
    "Let's calculate the number of tokens in our query:\n",
    "\n",
    "```python\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "```\n",
    "\n",
    "Use the `encode` function. How many tokens does our prompt have?\n",
    "\n",
    "* 122\n",
    "* 222\n",
    "* 322\n",
    "* 422\n",
    "\n",
    "Note: to decode back a token into a word, you can use the `decode_single_token_bytes` function:\n",
    "\n",
    "```python\n",
    "encoding.decode_single_token_bytes(63842)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ANS: 322"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
